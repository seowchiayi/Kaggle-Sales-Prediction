{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = pd.read_csv('./input/items.csv')\n",
    "df_categories = pd.read_csv('./input/item_categories.csv')\n",
    "df_shops = pd.read_csv('./input/shops.csv')\n",
    "df_train = pd.read_csv('./input/sales_train_v2.csv')\n",
    "df_test = pd.read_csv('./input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype=='float64']\n",
    "    int_cols = [c for c in df if df[c].dtype=='int64']\n",
    "\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.item_price<100000]\n",
    "df_train = df_train[df_train.item_cnt_day<=1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = df_train['date_block_num'].unique()\n",
    "index_cols = ['shop_id','item_id','date_block_num']\n",
    "\n",
    "combination = []\n",
    "for month in month_list:\n",
    "    shop_list = df_train.loc[df_train['date_block_num']==month, 'shop_id'].unique()\n",
    "    item_list = df_train.loc[df_train['date_block_num']==month, 'item_id'].unique()\n",
    "    combination.append(list(product(*[shop_list, item_list,[month]])))\n",
    "\n",
    "#Convert combinations to dataframe\n",
    "combination = pd.DataFrame(np.vstack(combination),columns = index_cols,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiayi/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py:4291: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Find item sold per month for each shop\n",
    "gb = df_train.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(combination,gb,how='left',on=index_cols).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiayi/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py:4291: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#shop-month aggregates\n",
    "gb = df_train.groupby(['shop_id','date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum','target_shop_avg':'mean'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data,gb,how='left',on=['shop_id','date_block_num']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiayi/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py:4291: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#item-month aggregates\n",
    "gb = df_train.groupby(['item_id','date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum','target_item_avg':'mean'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data,gb,how='left',on=['item_id','date_block_num']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = downcast_dtypes(all_data)\n",
    "del combination, gb\n",
    "\n",
    "#free memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_test = df_test.copy()\n",
    "tmp_test['date_block_num'] = 34\n",
    "tmp_test.drop('ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data,tmp_test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = list(all_data.columns.difference(index_cols))\n",
    "\n",
    "shift_range = [1,2,3,4,5,12]\n",
    "\n",
    "for month_shift in shift_range:\n",
    "    train_shift = all_data[cols_to_rename + index_cols].copy()\n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    rename = lambda x:'{}_lag_{}'.format(x,month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns = rename)\n",
    "    all_data = pd.merge(all_data, train_shift, on =index_cols,how='left').fillna(0)\n",
    "\n",
    "del train_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['sub_lag_1_2'] = all_data['target_lag_1'].subtract(all_data['target_lag_2'])\n",
    "all_data['sub_item_lag_1_2'] = all_data['target_item_lag_1'].subtract(all_data['target_item_lag_2'])\n",
    "all_data['sub_shop_lag_1_2'] = all_data['target_shop_lag_1'].subtract(all_data['target_shop_lag_2'])\n",
    "all_data['add_sub_lag_1_2_3_4'] = (all_data['target_lag_1'].add(all_data['target_lag_2'])).subtract(all_data['target_lag_3'].subtract(all_data['target_lag_4']))\n",
    "all_data['add_sub_item_lag_1_2_3_4'] = (all_data['target_item_lag_1'].add(all_data['target_item_lag_2'])).subtract(all_data['target_item_lag_3'] - all_data['target_item_lag_4'])\n",
    "all_data['add_sub_shop_lag_1_2_3_4'] = (all_data['target_shop_lag_1'].add(all_data['target_shop_lag_2'])).subtract(all_data['target_shop_lag_3'] - all_data['target_shop_lag_4'])\n",
    "all_data['mul_sub_lag_1_2'] = (all_data['target_lag_1']*2).subtract(all_data['target_lag_2'])\n",
    "all_data['mul_sub_item_lag_1_2'] = (all_data['target_item_lag_1']*2).subtract(all_data['target_item_lag_2'])\n",
    "all_data['mul_sub_shop_lag_1_2'] = (all_data['target_shop_lag_1']*2).subtract(all_data['target_shop_lag_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category for each item\n",
    "item_category_mapping = df_items[['item_id','item_category_id']].drop_duplicates()\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Encoding for item_id and shop_id\n",
    "for d in (all_data['date_block_num'].unique()):\n",
    "    item_id_target_mean = all_data[all_data.date_block_num<d].groupby('item_id').target.mean()\n",
    "    all_data.loc[all_data.date_block_num == d,'item_target_enc'] = all_data[all_data.date_block_num ==d]['item_id'].map(item_id_target_mean)\n",
    "    \n",
    "    shop_id_target_mean = all_data[all_data.date_block_num<d].groupby('shop_id').target.mean()\n",
    "    all_data.loc[all_data.date_block_num == d,'shop_target_enc'] = all_data[all_data.date_block_num ==d]['shop_id'].map(shop_id_target_mean)\n",
    "    \n",
    "    category_id_target_mean = all_data[all_data.date_block_num<d].groupby('item_category_id').target.mean()\n",
    "    all_data.loc[all_data.date_block_num == d,'category_target_enc'] = all_data[all_data.date_block_num ==d]['item_category_id'].map(category_id_target_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num']>12]\n",
    "\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]]\n",
    "\n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num']\n",
    "\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('all_data_new.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
